{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation (NMT) of names (cyrilic ->latin) using seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тук ще седи кратко описание на целия flow, от preprocessing до архитектурата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аамир Хан $ Aamir Khan\n",
      "Яя Туре $ Yaya Touré\n",
      "55496\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "with open(\"data/guessed-names.ru-en\") as names_file:\n",
    "    for line in names_file:\n",
    "        names.append(line)\n",
    "\n",
    "def replace_delimiter(data):\n",
    "    return [x.strip().replace(\"|||\", \"$\") for x in data]\n",
    "\n",
    "names = replace_delimiter(names)\n",
    "        \n",
    "print(names[0])\n",
    "print(names[-1])\n",
    "print(len(names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "15496\n"
     ]
    }
   ],
   "source": [
    "names_dev = names[:40000]\n",
    "names_test = names[39999:-1]\n",
    "print(len(names_dev))\n",
    "print(len(names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55496\n",
      "55496\n",
      "['Aamir Kha', 'Aarne Arvone', 'Aarne Pohjone', 'Aarne Salovaar', 'Aarno Ruusuvuor']\n"
     ]
    }
   ],
   "source": [
    "names_ru = [x[:x.index(\"$\")] for x in names]\n",
    "names_en = [x[x.index(\"$\")+2:-1] for x in names]\n",
    "print(len(names_ru))\n",
    "print(len(names_en))\n",
    "print(names_en[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тъй като моделът ще се опитва да предсказва t(i+1)-тата буква спрямо наличните ще е нужно да видим с какви букви ще се борави като цяло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аамир Хан \n",
      "$Aamir Kha#\n"
     ]
    }
   ],
   "source": [
    "input_text = names_ru\n",
    "# $ for start decoding and # for end\n",
    "target_text = [\"$\" + en + \"#\" for en in names_en]\n",
    "\n",
    "print(input_text[0])\n",
    "print(target_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '-', '.', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ы', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', '—']\n",
      "69\n",
      "[' ', '#', '$', '-', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'Á', 'Ä', 'Å', 'Ç', 'È', 'É', 'Ê', 'Í', 'Ð', 'Ñ', 'Ó', 'Õ', 'Ö', 'Ø', 'Ú', 'Ü', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ú', 'û', 'ü', 'ý', 'ÿ', 'Ā', 'ā', 'ă', 'ą', 'Ć', 'ć', 'Ċ', 'Č', 'č', 'Ď', 'ď', 'Đ', 'đ', 'Ē', 'ē', 'ĕ', 'ė', 'ę', 'ě', 'Ğ', 'ğ', 'Ģ', 'ģ', 'Ī', 'ī', 'İ', 'ı', 'Ķ', 'ķ', 'ļ', 'Ľ', 'ľ', 'Ł', 'ł', 'ń', 'ņ', 'ň', 'Ō', 'ō', 'ő', 'œ', 'Ř', 'ř', 'Ś', 'ś', 'Ş', 'ş', 'Š', 'š', 'Ţ', 'ţ', 'ť', 'Ū', 'ū', 'ŭ', 'ů', 'ű', 'ǎ', 'Ș', 'ș', 'Ț', 'ț']\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "input_ch = sorted(list(set([char for name in input_text for char in name ])))\n",
    "target_ch = sorted(list(set([char for name in target_text for char in name ])))\n",
    "\n",
    "print(input_ch)\n",
    "print(len(input_ch))\n",
    "print(target_ch)\n",
    "print(len(target_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ch_idx = dict([(char,i) for i, char in enumerate(input_ch)])\n",
    "target_ch_idx = dict([(char,i) for i, char in enumerate(target_ch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "max_encoder_name_len = max([len(name) for name in input_text])\n",
    "max_decoder_name_len = max([len(name) for name in target_text])\n",
    "\n",
    "print(max_encoder_name_len)\n",
    "print(max_decoder_name_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros ( (len(input_text), max_encoder_name_len, len(input_ch)) )\n",
    "decoder_input_data = np.zeros ( (len(input_text), max_decoder_name_len, len(target_ch)) )\n",
    "decoder_target_data = np.zeros( (len(input_text), max_decoder_name_len, len(target_ch)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55496, 33, 69)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55496, 33, 164)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55496, 33, 164)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_name, target_name) in enumerate(zip(input_text, target_text)):\n",
    "    for t, char in enumerate(input_name):\n",
    "        encoder_input_data[i, t, input_ch_idx[char]] = 1.\n",
    "    for t, char in enumerate(target_name):\n",
    "        decoder_input_data[i, t, target_ch_idx[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_ch_idx[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сега започваме да сглабяме encoder-decoder архитектурата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, len(input_ch)))\n",
    "encoder = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, len(target_ch)))\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(target_ch), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44396 samples, validate on 11100 samples\n",
      "Epoch 1/5\n",
      "44396/44396 [==============================] - 173s 4ms/step - loss: 1.1049 - val_loss: 1.0880\n",
      "Epoch 2/5\n",
      "44396/44396 [==============================] - 170s 4ms/step - loss: 0.9073 - val_loss: 1.1032\n",
      "Epoch 3/5\n",
      "44396/44396 [==============================] - 166s 4ms/step - loss: 0.8227 - val_loss: 1.0882\n",
      "Epoch 4/5\n",
      "44396/44396 [==============================] - 167s 4ms/step - loss: 0.7578 - val_loss: 1.1068\n",
      "Epoch 5/5\n",
      "44396/44396 [==============================] - 175s 4ms/step - loss: 0.7149 - val_loss: 1.0851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe9104b4080>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# `encoder_input_data` & `decoder_input_data` -> `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=64,\n",
    "          epochs=5,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-d4e4489e944f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ru-en.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2554\u001b[0m         \"\"\"\n\u001b[1;32m   2555\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2556\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_model` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_json_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "model.save('ru-en.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_ch_idx = dict(\n",
    "    (i, char) for char, i in input_ch_idx.items())\n",
    "reverse_target_ch_idx= dict(\n",
    "    (i, char) for char, i in target_ch_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  \n",
    "    target_seq = np.zeros((1, 1, len(target_ch)))\n",
    "   \n",
    "    target_seq[0, 0, target_ch_idx['$']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_ch_idx[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '#' or\n",
    "           len(decoded_sentence) > max_decoder_name_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, len(target_ch)))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Аамир Хан \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарне Арвонен \n",
      "Decoded sentence: Arthur Barri#\n",
      "-\n",
      "Input sentence: Аарне Похионен \n",
      "Decoded sentence: Arthur Barri#\n",
      "-\n",
      "Input sentence: Аарне Саловаара \n",
      "Decoded sentence: Arthur Barri#\n",
      "-\n",
      "Input sentence: Аарно Руусувуори \n",
      "Decoded sentence: Arthur Barri#\n",
      "-\n",
      "Input sentence: Аарно Юрьё-Коскинен \n",
      "Decoded sentence: Arthur Barri#\n",
      "-\n",
      "Input sentence: Аарон Авшаломов \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Александр \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Аппельфельд \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Арроусмит \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Барак \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Бёрр \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Буркхард \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Галиндо \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Гиллеспи \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Голдберг \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Гольдштейн \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Дауни \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Директор \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Зигман \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Картер \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Клафам \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Клуг \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Копленд \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Крикстейн \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Леннон \n",
      "Decoded sentence: Arthur Barte#\n",
      "-\n",
      "Input sentence: Аарон Льюис \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Норрис \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Норт \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Ньигес \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Пирсол \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Пол \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Розанд \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Ром \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Руссо \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Соркин \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Спеллинг \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Стейнторп \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Стэнфорд \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Тейлор-Джонсон \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Тёрнер \n",
      "Decoded sentence: Arthur Barte#\n",
      "-\n",
      "Input sentence: Аарон Финк \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Хант \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Хотер-Йишай \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Хьюз \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Хьюи \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Цизлинг \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Чехановер \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Шварц \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Экхарт \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Эшмор \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарон Ю \n",
      "Decoded sentence: Adrian Balla#\n",
      "-\n",
      "Input sentence: Аарре Мериканто \n",
      "Decoded sentence: Arthur Barri#\n",
      "-\n",
      "Input sentence: Аасиф Мандви \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Аатос Эркко \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Аафия Сиддики \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Аб Айверкс \n",
      "Decoded sentence: August Schele#\n",
      "-\n",
      "Input sentence: Абба Ахимеир \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абба Ковнер \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Аббас Доуран \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Аббас Карабаги \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Аббас Киаростами \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Аббас Маруфи \n",
      "Decoded sentence: August Schele#\n",
      "-\n",
      "Input sentence: Аббас Юсуф \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абба Эвен \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдалаати Игуйдер \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдалла Сенусси \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдалла Шлейфер \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абделатиф Кешиш \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абделила Бенкиран \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абделилах Сабер \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдельила Баги \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абделькадер Геззаль \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абделькадер Лафауи \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абделькарим Кисси \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдельмалек Селлаль \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдельхаким Омрани \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдельхамид Брахими \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдельхафид Бенчабла \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдеррахим Гюмри \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Абдеррахман Мажуб \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Абдеррахман Хаммад \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Абдеслам Уадду \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абди Биле \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Абдилачим Адеми \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдильда Тажибаев \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдихакем Абдирахман \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Абдолкарим Соруш \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абду Джамме \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Абду Диуф \n",
      "Decoded sentence: Adam Marti#\n",
      "-\n",
      "Input sentence: Абдулазиз аль-Джануби \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдулай Вад \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдулай Джире \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдулай Диань-Фай \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдулайе Ба \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдулайе Ибрагим \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдулай Конко \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдулай Мейте \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдула Сидран \n",
      "Decoded sentence: Adam Marte#\n",
      "-\n",
      "Input sentence: Абдул Вас \n",
      "Decoded sentence: Adam Marte#\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_text[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
