{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation (NMT) of names (cyrilic ->latin) using seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тук ще седи кратко описание на целия flow, от preprocessing до архитектурата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аамир Хан $ Aamir Khan\n",
      "Яя Туре $ Yaya Touré\n",
      "55496\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "with open(\"data/guessed-names.ru-en\") as names_file:\n",
    "    for line in names_file:\n",
    "        names.append(line)\n",
    "\n",
    "def replace_delimiter(data):\n",
    "    return [x.strip().replace(\"|||\", \"$\") for x in data]\n",
    "\n",
    "names = replace_delimiter(names)\n",
    "        \n",
    "print(names[0])\n",
    "print(names[-1])\n",
    "print(len(names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "15496\n"
     ]
    }
   ],
   "source": [
    "names_dev = names[:40000]\n",
    "names_test = names[39999:-1]\n",
    "print(len(names_dev))\n",
    "print(len(names_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55496\n",
      "55496\n",
      "['Aamir Kha', 'Aarne Arvone', 'Aarne Pohjone', 'Aarne Salovaar', 'Aarno Ruusuvuor']\n"
     ]
    }
   ],
   "source": [
    "names_ru = [x[:x.index(\"$\")] for x in names]\n",
    "names_en = [x[x.index(\"$\")+2:-1] for x in names]\n",
    "print(len(names_ru))\n",
    "print(len(names_en))\n",
    "print(names_en[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тъй като моделът ще се опитва да предсказва t(i+1)-тата буква спрямо наличните ще е нужно да видим с какви букви ще се борави като цяло"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аамир Хан \n",
      "$Aamir Kha#\n"
     ]
    }
   ],
   "source": [
    "input_text = names_ru\n",
    "# $ for start decoding and # for end\n",
    "target_text = [\"$\" + en + \"#\" for en in names_en]\n",
    "\n",
    "print(input_text[0])\n",
    "print(target_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '-', '.', 'Ё', 'А', 'Б', 'В', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'У', 'Ф', 'Х', 'Ц', 'Ч', 'Ш', 'Щ', 'Ы', 'Э', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', '—']\n",
      "69\n",
      "[' ', '#', '$', '-', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'Á', 'Ä', 'Å', 'Ç', 'È', 'É', 'Ê', 'Í', 'Ð', 'Ñ', 'Ó', 'Õ', 'Ö', 'Ø', 'Ú', 'Ü', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ú', 'û', 'ü', 'ý', 'ÿ', 'Ā', 'ā', 'ă', 'ą', 'Ć', 'ć', 'Ċ', 'Č', 'č', 'Ď', 'ď', 'Đ', 'đ', 'Ē', 'ē', 'ĕ', 'ė', 'ę', 'ě', 'Ğ', 'ğ', 'Ģ', 'ģ', 'Ī', 'ī', 'İ', 'ı', 'Ķ', 'ķ', 'ļ', 'Ľ', 'ľ', 'Ł', 'ł', 'ń', 'ņ', 'ň', 'Ō', 'ō', 'ő', 'œ', 'Ř', 'ř', 'Ś', 'ś', 'Ş', 'ş', 'Š', 'š', 'Ţ', 'ţ', 'ť', 'Ū', 'ū', 'ŭ', 'ů', 'ű', 'ǎ', 'Ș', 'ș', 'Ț', 'ț']\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "input_ch = sorted(list(set([char for name in input_text for char in name ])))\n",
    "target_ch = sorted(list(set([char for name in target_text for char in name ])))\n",
    "\n",
    "print(input_ch)\n",
    "print(len(input_ch))\n",
    "print(target_ch)\n",
    "print(len(target_ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ch_idx = dict([(char,i) for i, char in enumerate(input_ch)])\n",
    "target_ch_idx = dict([(char,i) for i, char in enumerate(target_ch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "max_encoder_name_len = max([len(name) for name in input_text])\n",
    "max_decoder_name_len = max([len(name) for name in target_text])\n",
    "\n",
    "print(max_encoder_name_len)\n",
    "print(max_decoder_name_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros ( (len(input_text), max_encoder_name_len, len(input_ch)),dtype=\"float64\" )\n",
    "decoder_input_data = np.zeros ( (len(input_text), max_decoder_name_len, len(target_ch)),dtype=\"float64\" )\n",
    "decoder_target_data = np.zeros( (len(input_text), max_decoder_name_len, len(target_ch)),dtype=\"float64\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55496, 33, 69)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55496, 33, 164)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55496, 33, 164)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_name, target_name) in enumerate(zip(input_text, target_text)):\n",
    "    for t, char in enumerate(input_name):\n",
    "        encoder_input_data[i, t, input_ch_idx[char]] = 1.\n",
    "    for t, char in enumerate(target_name):\n",
    "        decoder_input_data[i, t, target_ch_idx[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_ch_idx[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сега започваме да сглабяме encoder-decoder архитектурата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,LSTM, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_inputs = Input(shape=(None, len(input_ch)))\n",
    "encoder = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, len(target_ch)))\n",
    "dropout = Dropout(0.2)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dropout,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(target_ch), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# `encoder_input_data` & `decoder_input_data` -> `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 164)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None, 69)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 164)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 333824      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  431104      dropout_1[0][0]                  \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 164)    42148       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 807,076\n",
      "Trainable params: 807,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44396 samples, validate on 11100 samples\n",
      "Epoch 1/128\n",
      "44396/44396 [==============================] - 22s 497us/step - loss: 1.2141 - val_loss: 1.1532\n",
      "Epoch 2/128\n",
      "44396/44396 [==============================] - 20s 458us/step - loss: 1.0542 - val_loss: 1.1076\n",
      "Epoch 3/128\n",
      "42240/44396 [===========================>..] - ETA: 0s - loss: 1.0114"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=128,\n",
    "          epochs=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py:2344: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save('ru-en.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_ch_idx = dict(\n",
    "    (i, char) for char, i in input_ch_idx.items())\n",
    "reverse_target_ch_idx= dict(\n",
    "    (i, char) for char, i in target_ch_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  \n",
    "    target_seq = np.zeros((1, 1, len(target_ch)))\n",
    "   \n",
    "    target_seq[0, 0, target_ch_idx['$']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_ch_idx[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        \n",
    "        if (sampled_char == '#' or\n",
    "           len(decoded_sentence) > max_decoder_name_len):\n",
    "            stop_condition = True\n",
    "\n",
    "       \n",
    "        target_seq = np.zeros((1, 1, len(target_ch)))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Аамир Хан \n",
      "Decoded sentence: Amari Ha#\n",
      "-\n",
      "Input sentence: Аарне Арвонен \n",
      "Decoded sentence: Aarne Arvone#\n",
      "-\n",
      "Input sentence: Аарне Похионен \n",
      "Decoded sentence: Aarne Pochino#\n",
      "-\n",
      "Input sentence: Аарне Саловаара \n",
      "Decoded sentence: Aarne Salovaar#\n",
      "-\n",
      "Input sentence: Аарно Руусувуори \n",
      "Decoded sentence: Aarno Dulutmoniu#\n",
      "-\n",
      "Input sentence: Аарно Юрьё-Коскинен \n",
      "Decoded sentence: Aarno Guriosk-Chamse#\n",
      "-\n",
      "Input sentence: Аарон Авшаломов \n",
      "Decoded sentence: Aaron Aflasovi#\n",
      "-\n",
      "Input sentence: Аарон Александр \n",
      "Decoded sentence: Aaron Alexande#\n",
      "-\n",
      "Input sentence: Аарон Аппельфельд \n",
      "Decoded sentence: Aaron Appellibe#\n",
      "-\n",
      "Input sentence: Аарон Арроусмит \n",
      "Decoded sentence: Aaron Arrousmot#\n",
      "-\n",
      "Input sentence: Аарон Барак \n",
      "Decoded sentence: Aaron Bara#\n",
      "-\n",
      "Input sentence: Аарон Бёрр \n",
      "Decoded sentence: Aaron Bur#\n",
      "-\n",
      "Input sentence: Аарон Буркхард \n",
      "Decoded sentence: Aaron Burkahr#\n",
      "-\n",
      "Input sentence: Аарон Галиндо \n",
      "Decoded sentence: Aaron Galind#\n",
      "-\n",
      "Input sentence: Аарон Гиллеспи \n",
      "Decoded sentence: Aaron Gillespi#\n",
      "-\n",
      "Input sentence: Аарон Голдберг \n",
      "Decoded sentence: Aaron Goldbre#\n",
      "-\n",
      "Input sentence: Аарон Гольдштейн \n",
      "Decoded sentence: Aaron Goldstei#\n",
      "-\n",
      "Input sentence: Аарон Дауни \n",
      "Decoded sentence: Aaron Downi#\n",
      "-\n",
      "Input sentence: Аарон Директор \n",
      "Decoded sentence: Aaron Dirkert#\n",
      "-\n",
      "Input sentence: Аарон Зигман \n",
      "Decoded sentence: Aaron Zigma#\n",
      "-\n",
      "Input sentence: Аарон Картер \n",
      "Decoded sentence: Aaron Carte#\n",
      "-\n",
      "Input sentence: Аарон Клафам \n",
      "Decoded sentence: Aaron Clafa#\n",
      "-\n",
      "Input sentence: Аарон Клуг \n",
      "Decoded sentence: Aaron Klu#\n",
      "-\n",
      "Input sentence: Аарон Копленд \n",
      "Decoded sentence: Aaron Coplen#\n",
      "-\n",
      "Input sentence: Аарон Крикстейн \n",
      "Decoded sentence: Aaron Crickstei#\n",
      "-\n",
      "Input sentence: Аарон Леннон \n",
      "Decoded sentence: Aaron Lenno#\n",
      "-\n",
      "Input sentence: Аарон Льюис \n",
      "Decoded sentence: Aarond Leuic#\n",
      "-\n",
      "Input sentence: Аарон Норрис \n",
      "Decoded sentence: Aaron Norri#\n",
      "-\n",
      "Input sentence: Аарон Норт \n",
      "Decoded sentence: Aaron Nort#\n",
      "-\n",
      "Input sentence: Аарон Ньигес \n",
      "Decoded sentence: Aaron Nige#\n",
      "-\n",
      "Input sentence: Аарон Пирсол \n",
      "Decoded sentence: Aaron Pirso#\n",
      "-\n",
      "Input sentence: Аарон Пол \n",
      "Decoded sentence: Aaron Paul#\n",
      "-\n",
      "Input sentence: Аарон Розанд \n",
      "Decoded sentence: Aaron Rosan#\n",
      "-\n",
      "Input sentence: Аарон Ром \n",
      "Decoded sentence: Aaron Roh#\n",
      "-\n",
      "Input sentence: Аарон Руссо \n",
      "Decoded sentence: Aaron Russ#\n",
      "-\n",
      "Input sentence: Аарон Соркин \n",
      "Decoded sentence: Aaron Sorki#\n",
      "-\n",
      "Input sentence: Аарон Спеллинг \n",
      "Decoded sentence: Aaron Spellin#\n",
      "-\n",
      "Input sentence: Аарон Стейнторп \n",
      "Decoded sentence: Aaron Steintor#\n",
      "-\n",
      "Input sentence: Аарон Стэнфорд \n",
      "Decoded sentence: Aaron Stanfro#\n",
      "-\n",
      "Input sentence: Аарон Тейлор-Джонсон \n",
      "Decoded sentence: Aaron Taylor-Johnsk#\n",
      "-\n",
      "Input sentence: Аарон Тёрнер \n",
      "Decoded sentence: Aaron Turne#\n",
      "-\n",
      "Input sentence: Аарон Финк \n",
      "Decoded sentence: Aaron Fin#\n",
      "-\n",
      "Input sentence: Аарон Хант \n",
      "Decoded sentence: Aaron Hun#\n",
      "-\n",
      "Input sentence: Аарон Хотер-Йишай \n",
      "Decoded sentence: Aaron Hother-Rise#\n",
      "-\n",
      "Input sentence: Аарон Хьюз \n",
      "Decoded sentence: Aaron Hus#\n",
      "-\n",
      "Input sentence: Аарон Хьюи \n",
      "Decoded sentence: Aaron Hui#\n",
      "-\n",
      "Input sentence: Аарон Цизлинг \n",
      "Decoded sentence: Aaron Zislin#\n",
      "-\n",
      "Input sentence: Аарон Чехановер \n",
      "Decoded sentence: Aaron Cechanove#\n",
      "-\n",
      "Input sentence: Аарон Шварц \n",
      "Decoded sentence: Aaron Swart#\n",
      "-\n",
      "Input sentence: Аарон Экхарт \n",
      "Decoded sentence: Aaron Ekshar#\n",
      "-\n",
      "Input sentence: Аарон Эшмор \n",
      "Decoded sentence: Aaron Esmor#\n",
      "-\n",
      "Input sentence: Аарон Ю \n",
      "Decoded sentence: Aaron Yo#\n",
      "-\n",
      "Input sentence: Аарре Мериканто \n",
      "Decoded sentence: Harra Merikant#\n",
      "-\n",
      "Input sentence: Аасиф Мандви \n",
      "Decoded sentence: Aasif Mandwi#\n",
      "-\n",
      "Input sentence: Аатос Эркко \n",
      "Decoded sentence: Aatos Erkk#\n",
      "-\n",
      "Input sentence: Аафия Сиддики \n",
      "Decoded sentence: Aafia Siddia#\n",
      "-\n",
      "Input sentence: Аб Айверкс \n",
      "Decoded sentence: Ab Iwerk#\n",
      "-\n",
      "Input sentence: Абба Ахимеир \n",
      "Decoded sentence: Abba Ahimie#\n",
      "-\n",
      "Input sentence: Абба Ковнер \n",
      "Decoded sentence: Abba Kovne#\n",
      "-\n",
      "Input sentence: Аббас Доуран \n",
      "Decoded sentence: Abbas Dowra#\n",
      "-\n",
      "Input sentence: Аббас Карабаги \n",
      "Decoded sentence: Abbas Carabag#\n",
      "-\n",
      "Input sentence: Аббас Киаростами \n",
      "Decoded sentence: Abbas Kiarossab#\n",
      "-\n",
      "Input sentence: Аббас Маруфи \n",
      "Decoded sentence: Abbas Marwoi#\n",
      "-\n",
      "Input sentence: Аббас Юсуф \n",
      "Decoded sentence: Abbas Husu#\n",
      "-\n",
      "Input sentence: Абба Эвен \n",
      "Decoded sentence: Abba Ebe#\n",
      "-\n",
      "Input sentence: Абдалаати Игуйдер \n",
      "Decoded sentence: Abdalaati Iguide#\n",
      "-\n",
      "Input sentence: Абдалла Сенусси \n",
      "Decoded sentence: Abdalla Senuss#\n",
      "-\n",
      "Input sentence: Абдалла Шлейфер \n",
      "Decoded sentence: Abdallah Schleife#\n",
      "-\n",
      "Input sentence: Абделатиф Кешиш \n",
      "Decoded sentence: Abdellatien Keschic#\n",
      "-\n",
      "Input sentence: Абделила Бенкиран \n",
      "Decoded sentence: Abdelila Benkirn#\n",
      "-\n",
      "Input sentence: Абделилах Сабер \n",
      "Decoded sentence: Abdelliah Sabe#\n",
      "-\n",
      "Input sentence: Абдельила Баги \n",
      "Decoded sentence: Abdelilah Bag#\n",
      "-\n",
      "Input sentence: Абделькадер Геззаль \n",
      "Decoded sentence: Abdelaked Ghezze#\n",
      "-\n",
      "Input sentence: Абделькадер Лафауи \n",
      "Decoded sentence: Abdellatha Dausba#\n",
      "-\n",
      "Input sentence: Абделькарим Кисси \n",
      "Decoded sentence: Abdellaine Cliss#\n",
      "-\n",
      "Input sentence: Абдельмалек Селлаль \n",
      "Decoded sentence: Abdelmalie Slele#\n",
      "-\n",
      "Input sentence: Абдельхаким Омрани \n",
      "Decoded sentence: Abdelkhamid Horman#\n",
      "-\n",
      "Input sentence: Абдельхамид Брахими \n",
      "Decoded sentence: Abdelhamid Brahim#\n",
      "-\n",
      "Input sentence: Абдельхафид Бенчабла \n",
      "Decoded sentence: Abdelhatim Benkhabo#\n",
      "-\n",
      "Input sentence: Абдеррахим Гюмри \n",
      "Decoded sentence: Abderrahim Gumir#\n",
      "-\n",
      "Input sentence: Абдеррахман Мажуб \n",
      "Decoded sentence: Abderrahman Mowe#\n",
      "-\n",
      "Input sentence: Абдеррахман Хаммад \n",
      "Decoded sentence: Abderrahmane Gamma#\n",
      "-\n",
      "Input sentence: Абдеслам Уадду \n",
      "Decoded sentence: Abdeslam Waddo#\n",
      "-\n",
      "Input sentence: Абди Биле \n",
      "Decoded sentence: Adbi Bil#\n",
      "-\n",
      "Input sentence: Абдилачим Адеми \n",
      "Decoded sentence: Abdilachim Adem#\n",
      "-\n",
      "Input sentence: Абдильда Тажибаев \n",
      "Decoded sentence: Abdillahd Taizaba#\n",
      "-\n",
      "Input sentence: Абдихакем Абдирахман \n",
      "Decoded sentence: Abdihaked Abiharbia#\n",
      "-\n",
      "Input sentence: Абдолкарим Соруш \n",
      "Decoded sentence: Abdollabir Zoru#\n",
      "-\n",
      "Input sentence: Абду Джамме \n",
      "Decoded sentence: Abdou Jamm#\n",
      "-\n",
      "Input sentence: Абду Диуф \n",
      "Decoded sentence: Abdou Diou#\n",
      "-\n",
      "Input sentence: Абдулазиз аль-Джануби \n",
      "Decoded sentence: Abdulzahie Al-Zanba#\n",
      "-\n",
      "Input sentence: Абдулай Вад \n",
      "Decoded sentence: Abdulah Wa#\n",
      "-\n",
      "Input sentence: Абдулай Джире \n",
      "Decoded sentence: Abdoulayn Eir#\n",
      "-\n",
      "Input sentence: Абдулай Диань-Фай \n",
      "Decoded sentence: Abdoulaye Finaya#\n",
      "-\n",
      "Input sentence: Абдулайе Ба \n",
      "Decoded sentence: Abdoulaie B#\n",
      "-\n",
      "Input sentence: Абдулайе Ибрагим \n",
      "Decoded sentence: Abdulahie Ibrahi#\n",
      "-\n",
      "Input sentence: Абдулай Конко \n",
      "Decoded sentence: Abdoulay Konk#\n",
      "-\n",
      "Input sentence: Абдулай Мейте \n",
      "Decoded sentence: Abdulay Meit#\n",
      "-\n",
      "Input sentence: Абдула Сидран \n",
      "Decoded sentence: Abdulah Sierda#\n",
      "-\n",
      "Input sentence: Абдул Вас \n",
      "Decoded sentence: Abdul Was#\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_text[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Аамир Хан '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"Николай Чакъров\"\n",
    "encoded = np.zeros ( (1, max_encoder_name_len, len(input_ch)),dtype=\"float64\" )\n",
    "for t, char in enumerate(input_name):\n",
    "        encoded[0, t, input_ch_idx[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nikolaj Čakri#'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence((encoded[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16209706778565432366\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5526781952\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 9629034338403934512\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
