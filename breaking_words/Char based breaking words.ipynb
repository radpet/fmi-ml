{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO, StringIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract(url, path):\n",
    "    request = requests.get(url)\n",
    "    with ZipFile(BytesIO(request.content), \"r\") as file:\n",
    "         file.extractall(path)\n",
    "\n",
    "urls = [\n",
    "    \"https://chitanka.info/book/25-andersenovi-prikazki.txt.zip\",\n",
    "    \"https://chitanka.info/book/3103-601-izpitani-gotvarski-retsepti.txt.zip\",\n",
    "    \"https://chitanka.info/book/6393-bogat-tatko-beden-tatko.txt.zip\",\n",
    "    \"https://chitanka.info/book/524-az-i-moreto.txt.zip\",\n",
    "    \"https://chitanka.info/book/6548-baba-djado-i-vnuche.txt.zip\",\n",
    "    \"https://chitanka.info/book/6938-12-printsipa-na-proizvoditelnostta.txt.zip\",\n",
    "    \"https://chitanka.info/book/1581-igrata-na-lisitsite.txt.zip\",\n",
    "    \"https://chitanka.info/book/8106-usmivka-v-polunosht.txt.zip\",\n",
    "]\n",
    "            \n",
    "for url in urls:\n",
    "    download_and_extract(url,\"./training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_line_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(path, files=os.listdir(\"./training/\")):\n",
    "    lines = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(\"./training/{}\".format(file), encoding=\"utf-8-sig\") as file_content:\n",
    "            for line in file_content:\n",
    "                line = line.strip()\n",
    "                if(len(line) > max_line_len):\n",
    "                    tokens = line.split(\" \")\n",
    "                    new_line = \"\"\n",
    "                    for token in tokens:\n",
    "                        if(len(new_line) + len(token) < max_line_len):\n",
    "                            new_line +=token + \" \"\n",
    "                        else:\n",
    "                            lines.append(new_line)\n",
    "                            new_line = \"\"\n",
    "                else:\n",
    "                    if len(line) > 3:\n",
    "                        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = read_corpus(\"./training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52963"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Пенка Чолчева. 601 изпитани готварски рецепти',\n",
       " 'Съставител: Ани Чолчева',\n",
       " 'Издадена от списание „Стил“, София, 1991.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [ line.replace(\" \", \"\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_CHAR = \"\\t\"\n",
    "END_CHAR = \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = [ START_CHAR + line + END_CHAR for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Баба,дядоивнуче', 'Народниприказки', 'НиколайХайтов']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ch = set()\n",
    "for line in input_text:\n",
    "    for c in line:\n",
    "        input_ch.add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ch = list(sorted(input_ch))\n",
    "input_ch_len = len(input_ch)\n",
    "input_ch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ch = set()\n",
    "for line in target_text:\n",
    "    for c in line:\n",
    "        target_ch.add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ch_len = len(target_ch)\n",
    "target_ch_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ch_idx = dict([(char,i) for i, char in enumerate(input_ch)])\n",
    "target_ch_idx = dict([(char,i) for i, char in enumerate(target_ch)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "max_input_len = max([len(line) for line in input_text])\n",
    "max_target_len = max([len(line) for line in target_text])\n",
    "\n",
    "print(max_input_len)\n",
    "print(max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros ( (len(input_text), max_input_len, input_ch_len ),dtype=\"float64\" )\n",
    "decoder_input_data = np.zeros ( (len(input_text), max_target_len, target_ch_len ),dtype=\"float64\" )\n",
    "decoder_target_data = np.zeros( (len(input_text), max_target_len, target_ch_len ),dtype=\"float64\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52963, 46, 167)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52963, 52, 170)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52963, 52, 170)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_name, target_name) in enumerate(zip(input_text, target_text)):\n",
    "    for t, char in enumerate(input_name):\n",
    "        encoder_input_data[i, t, input_ch_idx[char]] = 1.\n",
    "    for t, char in enumerate(target_name):\n",
    "        decoder_input_data[i, t, target_ch_idx[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_ch_idx[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,LSTM, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_SPACE_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, input_ch_len))\n",
    "encoder = LSTM(STATE_SPACE_DIM, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, target_ch_len))\n",
    "dropout = Dropout(0.2)(decoder_inputs)\n",
    "decoder_lstm = LSTM(STATE_SPACE_DIM, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dropout,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(target_ch_len, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 170)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, None, 167)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 170)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 434176      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  437248      dropout_1[0][0]                  \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 170)    43690       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 915,114\n",
      "Trainable params: 915,114\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42370 samples, validate on 10593 samples\n",
      "Epoch 1/2\n",
      "42370/42370 [==============================] - 18s 427us/step - loss: 0.2721 - val_loss: 0.4498\n",
      "Epoch 2/2\n",
      "42370/42370 [==============================] - 18s 426us/step - loss: 0.2664 - val_loss: 0.4449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99a7ea07b8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=256,\n",
    "          epochs=2,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py:2344: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save(\"char_based_rnn_more_data_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(STATE_SPACE_DIM,))\n",
    "decoder_state_input_c = Input(shape=(STATE_SPACE_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_ch_idx = dict(\n",
    "    (i, char) for char, i in input_ch_idx.items())\n",
    "reverse_target_ch_idx= dict(\n",
    "    (i, char) for char, i in target_ch_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  \n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  \n",
    "    target_seq = np.zeros((1, 1, len(target_ch)))\n",
    "   \n",
    "    target_seq[0, 0, target_ch_idx['$']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_ch_idx[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        \n",
    "        if (sampled_char == END_CHAR or\n",
    "           len(decoded_sentence) > max_target_len):\n",
    "            stop_condition = True\n",
    "\n",
    "       \n",
    "        target_seq = np.zeros((1, 1, len(target_ch)))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_text[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(input_name):\n",
    "    encoded = np.zeros (( 1 , max_input_len, input_ch_len ),dtype=\"float64\" )\n",
    "    for t, char in enumerate(input_name):\n",
    "        encoded[0, t, input_ch_idx[char]] = 1.\n",
    "    return encoded[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "да сгеживи издрави\n",
      "\n",
      "за много години\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decode_sequence(encode(\"дасмеживииздрави\")))\n",
    "print(decode_sequence(encode(\"замногогодини\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
