{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col=\"PassengerId\")\n",
    "train_no_survived = train.drop(\"Survived\", axis=1);\n",
    "\n",
    "submission_dataset = pd.read_csv(\"test.csv\") \n",
    "\n",
    "dataset = train_no_survived.append(submission_dataset.drop(\"PassengerId\", axis=1))\n",
    "\n",
    "title_list = [\"Mr.\", \"Master.\", \"Mrs.\", \"Miss.\"]\n",
    "    \n",
    "    # http://grammarist.com/usage/mr-mrs-ms-and-miss/\n",
    "def map_names(name):\n",
    "    for title in title_list:\n",
    "        if title in name:\n",
    "            return title\n",
    "    return \"Unknown\"\n",
    "            \n",
    "dataset[\"Name\"] = dataset[\"Name\"].map(map_names)\n",
    "    \n",
    "def slice_and_get_mean_age_by_name(name):\n",
    "    return dataset.loc[dataset[\"Name\"] == name, \"Age\"].mean()\n",
    "    \n",
    "age_means = {k:slice_and_get_mean_age_by_name(k) for k in [\"Mr.\", \"Master.\", \"Mrs.\", \"Miss.\", \"Unknown\"]}\n",
    "\n",
    "\n",
    "def fill_age(row):\n",
    "    if np.isnan(row[3]):\n",
    "        row[3] = age_means[row[1]]\n",
    "    return row\n",
    "\n",
    "dataset = dataset.apply(fill_age, axis=1)\n",
    "\n",
    "dataset[\"Fare\"] = dataset[\"Fare\"].fillna(dataset[\"Fare\"].mean())\n",
    "\n",
    "cabin_list = list(\"ABCDEFTG\")\n",
    "def map_cabin(cabin):\n",
    "    return str(cabin)\n",
    "    \n",
    "dataset[\"Cabin\"] = dataset[\"Cabin\"].fillna(\"\")\n",
    "    \n",
    "towns = list(\"CQS\")\n",
    "dataset[\"Embarked\"] = dataset[\"Embarked\"].fillna(random.choice(towns))\n",
    "\n",
    "categorical_columns = [\"Embarked\", \"Sex\", \"Cabin\", \"Name\"];\n",
    "\n",
    "encoders = {col: LabelEncoder().fit(dataset[col]) for col in categorical_columns}\n",
    "\n",
    "def encode_categorical(data, columns, encoders):\n",
    "    return pd.DataFrame({col: encoders[col].transform(data[col]) for col in columns},\n",
    "                        index = data.index)\n",
    "\n",
    "encoded = encode_categorical(dataset, categorical_columns , encoders)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder().fit(encoded)\n",
    "\n",
    "\n",
    "train_data_cleaned = dataset[0:-418]\n",
    "\n",
    "test_data_cleaned_for_submission = dataset.tail(418)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(668, 3) (223, 3)\n",
      "(668, 197) (223, 197)\n",
      "(668, 202) (223, 202)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X , test_X, train_y, test_y = train_test_split(train_data_cleaned, train[\"Survived\"] , random_state=26)\n",
    "\n",
    "one_hot_X_train = one_hot_encoder.transform(encode_categorical(train_X[categorical_columns], categorical_columns, encoders))\n",
    "one_hot_X_test = one_hot_encoder.transform(encode_categorical(test_X[categorical_columns], categorical_columns, encoders))\n",
    "\n",
    "print(\"{} {}\".format(train_X[numeric_columns].shape, test_X[numeric_columns].shape))\n",
    "print(\"{} {}\".format(one_hot_X_train.shape, one_hot_X_test.shape))\n",
    "\n",
    "numeric_columns = [\"Pclass\", \"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "# train_X[\"Family\"] = train_X[\"SibSp\"] + train_X[\"Parch\"]\n",
    "# train_X = train_X.drop([\"SibSp\", \"Parch\"], axis=1)\n",
    "\n",
    "# test_X[\"Family\"] = test_X[\"SibSp\"] + test_X[\"Parch\"]\n",
    "# test_X = test_X.drop([\"SibSp\", \"Parch\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_X = np.concatenate([train_X[numeric_columns], one_hot_X_train.toarray()], axis=1);\n",
    "test_X = np.concatenate([test_X[numeric_columns], one_hot_X_test.toarray()], axis=1)\n",
    "\n",
    "print(\"{} {}\".format(train_X.shape, test_X.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is 0.8562874251497006\n",
      "Test score is 0.8340807174887892\n",
      "\n",
      "using alpha = 100\n",
      "Train score is 0.8233532934131736\n",
      "Test score is 0.8161434977578476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "def print_score(train, test):\n",
    "    print(\"Train score is {}\".format(train))\n",
    "    print(\"Test score is {}\".format(test))\n",
    "    print(\"\")\n",
    "\n",
    "print_score(model.score(train_X, train_y), model.score(test_X, test_y))\n",
    "#alphas = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "alphas = [100]\n",
    "for alpha in alphas:\n",
    "    \n",
    "    from sklearn.linear_model import RidgeClassifier\n",
    "    model2 = RidgeClassifier(alpha)\n",
    "    model2.fit(train_X, train_y)\n",
    "    print(\"using alpha = {}\".format(alpha))\n",
    "    print(\"Train score is {}\".format(model2.score(train_X, train_y)))\n",
    "    print(\"Test score is {}\".format(model2.score(test_X, test_y)))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is 0.8098802395209581\n",
      "Test score is 0.7040358744394619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(train_X, train_y)\n",
    "\n",
    "print_score(knn_model.score(train_X, train_y), knn_model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is 0.9730538922155688\n",
      "Test score is 0.7982062780269058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_f_model = RandomForestClassifier(random_state=0)\n",
    "random_f_model.fit(train_X, train_y)\n",
    "\n",
    "print_score(random_f_model.score(train_X, train_y), random_f_model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_test_data = one_hot_encoder.transform(encode_categorical(test_data_cleaned_for_submission[categorical_columns], categorical_columns, encoders))\n",
    "\n",
    "test_data_processed = np.concatenate([test_data_cleaned_for_submission[numeric_columns], one_hot_test_data.toarray()], axis=1);\n",
    "\n",
    "#prediction = random_f_model.predict(test_data_processed)\n",
    "#prediction = model2.predict(test_data_processed)\n",
    "prediction = model.predict(test_data_processed)\n",
    "\n",
    "def save(prediction):\n",
    "    df = pd.DataFrame(data={\"Survived\": prediction}, index=submission_dataset[\"PassengerId\"])\n",
    "    df.to_csv(\"with_data_cleaning.csv\")\n",
    "\n",
    "save(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv(\"train.csv\", index_col=\"PassengerId\")\n",
    "\n",
    "\n",
    "# print(\"Initial dataset shape:{}\".format(dataset.shape))\n",
    "# #print(dataset.head())\n",
    "# def pipe(dataset):\n",
    "    \n",
    "#     y = dataset[\"Survived\"]\n",
    "#     dataset = dataset.drop([\"Survived\"], axis=1)\n",
    "#     x = pretify(dataset, False)\n",
    "#     return (x,y)\n",
    "\n",
    "# ohe = OneHotEncoder()\n",
    "# le = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "# def pretify(dataset, prod=True):\n",
    "#     title_list = [\"Mr.\", \"Master.\", \"Mrs.\", \"Miss.\"]\n",
    "    \n",
    "#     # http://grammarist.com/usage/mr-mrs-ms-and-miss/\n",
    "#     def map_names(name):\n",
    "#         for title in title_list:\n",
    "#             if title in name:\n",
    "#                 return title\n",
    "#         return \"Unknown\"\n",
    "            \n",
    "#     dataset[\"Name\"] = dataset[\"Name\"].map(map_names)\n",
    "    \n",
    "#     print(dataset[\"Name\"].value_counts())\n",
    "#     def slice_and_get_mean_age_by_name(name):\n",
    "#         return dataset.loc[dataset[\"Name\"] == name, \"Age\"].mean()\n",
    "    \n",
    "#     age_means = {k:slice_and_get_mean_age_by_name(k) for k in [\"Mr.\", \"Master.\", \"Mrs.\", \"Miss.\", \"Unknown\"]}\n",
    "    \n",
    "#     def fill_age(row):\n",
    "#         if np.isnan(row[3]):\n",
    "#             row[3] = age_means[row[1]]\n",
    "#         return row\n",
    "        \n",
    "#     dataset = dataset.apply(fill_age, axis=1)\n",
    "    \n",
    "#     x = dataset.drop([\"Cabin\", \"Embarked\",\"Sex\", \"Ticket\", \"Name\"], axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "#     ix=[i for i in dataset.columns if i in [\"Embarked\", \"Sex\", \"Cabin\", \"Name\"]]\n",
    "    \n",
    "#     x_cat = dataset[ix];\n",
    "    \n",
    "#     cabin_list = list(\"ABCDEFTG\")\n",
    "#     def map_cabin(cabin):\n",
    "#         return str(cabin)\n",
    "    \n",
    "#     x_cat[\"Cabin\"] = x_cat[\"Cabin\"].map(map_cabin)\n",
    "    \n",
    "#     towns = list(\"CQS\")\n",
    "#     x_cat[\"Embarked\"] = x_cat[\"Embarked\"].fillna(random.choice(towns))\n",
    "    \n",
    "#     x_cat = x_cat.apply(le.fit_transform)\n",
    "    \n",
    "# #     if not prod:\n",
    "# #         x_cat.apply((lambda col: le.fit(col)))\n",
    "        \n",
    "# #     x_cat = x_cat.apply(le.transform)\n",
    "    \n",
    "#     if not prod:\n",
    "#         ohe.fit(x_cat)\n",
    "    \n",
    "#     x_cat_encoded = ohe.transform(x_cat)\n",
    "#     x = np.column_stack((x, x_cat_encoded.toarray()))\n",
    "    \n",
    "    \n",
    "#     return x\n",
    "\n",
    "# dataset_X, dataset_y = pipe(dataset)\n",
    "# print(dataset_X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
