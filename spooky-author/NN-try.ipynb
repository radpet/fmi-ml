{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19579, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inexpressible': 12903,\n",
       " 'mahmoud': 15025,\n",
       " 'translator': 25496,\n",
       " 'at': 1620,\n",
       " 'tumbling': 25767,\n",
       " 'contents': 5189,\n",
       " 'oslo': 17287,\n",
       " 'irregularity': 13535,\n",
       " 'singer': 22655,\n",
       " 'mourners': 16139,\n",
       " 'gorge': 10939,\n",
       " 'outspeeded': 17386,\n",
       " 'bulk': 3229,\n",
       " 'alarmed': 645,\n",
       " 'coaches': 4458,\n",
       " 'bondage': 2819,\n",
       " 'macabre': 14952,\n",
       " 'lungs': 14893,\n",
       " 'horthath': 12073,\n",
       " 'economics': 7884,\n",
       " 'prevailed': 19187,\n",
       " 'accorded': 181,\n",
       " 'meddling': 15433,\n",
       " 'items': 13607,\n",
       " 'disquisition': 7190,\n",
       " 'literally': 14613,\n",
       " 'past': 17841,\n",
       " 'effect': 7944,\n",
       " 'northerly': 16724,\n",
       " 'standards': 23515,\n",
       " 'dripping': 7601,\n",
       " 'expectations': 9020,\n",
       " 'report': 20697,\n",
       " 'confirmation': 4953,\n",
       " 'cameleopards': 3454,\n",
       " 'infallible': 12910,\n",
       " 'swelters': 24390,\n",
       " 'scrap': 21870,\n",
       " 'debris': 6138,\n",
       " 'reheaded': 20461,\n",
       " 'yxu': 28227,\n",
       " 'crazed': 5605,\n",
       " 'wearin': 27544,\n",
       " 'peeled': 17983,\n",
       " 'unnaturally': 26407,\n",
       " 'uncomfortably': 26029,\n",
       " 'credential': 5632,\n",
       " 'preposterous': 19119,\n",
       " 'break': 3002,\n",
       " 'ruler': 21405,\n",
       " 'disgusted': 7080,\n",
       " 'buildings': 3220,\n",
       " 'husbandmen': 12222,\n",
       " 'admit': 367,\n",
       " 'per': 18066,\n",
       " 'villager': 27123,\n",
       " 'bedroom': 2251,\n",
       " 'knife': 14001,\n",
       " 'softening': 22999,\n",
       " 'preferable': 19074,\n",
       " 'inglitch': 12999,\n",
       " 'entities': 8511,\n",
       " 'unwound': 26671,\n",
       " 'enwoven': 8563,\n",
       " 'ef': 7939,\n",
       " 'preston': 19161,\n",
       " 'blasting': 2639,\n",
       " 'determining': 6695,\n",
       " 'boullard': 2909,\n",
       " 'recording': 20289,\n",
       " 'brilliance': 3080,\n",
       " 'propontis': 19460,\n",
       " 'forbear': 10019,\n",
       " 'torch': 25309,\n",
       " 'deal': 6104,\n",
       " 'laconically': 14081,\n",
       " 'zigzagging': 28263,\n",
       " 'juan': 13788,\n",
       " 'sketchy': 22720,\n",
       " 'whites': 27741,\n",
       " 'main': 15040,\n",
       " 'infusions': 12990,\n",
       " 'national': 16402,\n",
       " 'capricious': 3559,\n",
       " 'composite': 4791,\n",
       " 'preparations': 19106,\n",
       " 'gott': 10959,\n",
       " 'outskirts': 17384,\n",
       " 'ninth': 16641,\n",
       " 'surgery': 24259,\n",
       " 'mongrelised': 15950,\n",
       " 'thinned': 24972,\n",
       " 'coffee': 4499,\n",
       " 'tartarus': 24619,\n",
       " 'undefined': 26079,\n",
       " 'food': 9986,\n",
       " 'trained': 25426,\n",
       " 'squawking': 23440,\n",
       " 'converge': 5274,\n",
       " 'rival': 21182,\n",
       " 'surgical': 24261,\n",
       " 'thames': 24864,\n",
       " 'kings': 13959,\n",
       " 'professional': 19341,\n",
       " 'guido': 11248,\n",
       " 'lurking': 14904,\n",
       " 'whiffs': 27680,\n",
       " 'kbanah': 13884,\n",
       " 'hampden': 11391,\n",
       " 'phlegethon': 18349,\n",
       " 'shirts': 22393,\n",
       " 'playthings': 18622,\n",
       " 'marine': 15216,\n",
       " 'labor': 14052,\n",
       " 'babbled': 1902,\n",
       " 'midsummer': 15661,\n",
       " 'historians': 11904,\n",
       " 'site': 22686,\n",
       " 'depending': 6484,\n",
       " 'warming': 27436,\n",
       " 'blissful': 2689,\n",
       " 'recognizes': 20255,\n",
       " 'aggressions': 559,\n",
       " 'reduplication': 20341,\n",
       " 'invaluable': 13437,\n",
       " 'sciences': 21820,\n",
       " 'folk': 9965,\n",
       " 'tessellated': 24838,\n",
       " 'pendulums': 18027,\n",
       " 'blotted': 2722,\n",
       " 'our': 17320,\n",
       " 'mentions': 15545,\n",
       " 'terminates': 24804,\n",
       " 'coal': 4462,\n",
       " 'lining': 14565,\n",
       " 'diversity': 7307,\n",
       " 'brief': 3060,\n",
       " 'privateers': 19269,\n",
       " 'instigate': 13198,\n",
       " 'approve': 1243,\n",
       " 'seulement': 22229,\n",
       " 'balancing': 1964,\n",
       " 'overturned': 17489,\n",
       " 'referred': 20366,\n",
       " 'cancer': 3484,\n",
       " 'bacchanalian': 1919,\n",
       " 'choaking': 4130,\n",
       " 'overt': 17472,\n",
       " 'gentlemen': 10656,\n",
       " 'aërial': 1896,\n",
       " 'carolina': 3626,\n",
       " 'allusion': 763,\n",
       " 'diddle': 6811,\n",
       " 'palm': 17618,\n",
       " 'seventeen': 22232,\n",
       " 'poete': 18715,\n",
       " 'tendre': 24765,\n",
       " 'wizards': 27933,\n",
       " 'neither': 16512,\n",
       " 'carefully': 3604,\n",
       " 'cipher': 4202,\n",
       " 'pres': 19121,\n",
       " 'charactery': 3942,\n",
       " 'caput': 3578,\n",
       " 'confronted': 4971,\n",
       " 'dared': 6021,\n",
       " 'towards': 25375,\n",
       " 'incense': 12667,\n",
       " 'victorious': 27085,\n",
       " 'degradation': 6308,\n",
       " 'sordid': 23116,\n",
       " 'guess': 11233,\n",
       " 'jug': 13800,\n",
       " 'shot': 22435,\n",
       " 'change': 3900,\n",
       " 'general': 10626,\n",
       " 'cassini': 3684,\n",
       " 'pungencies': 19680,\n",
       " 'agog': 573,\n",
       " 'curl': 5852,\n",
       " 'multiplied': 16196,\n",
       " 'steed': 23605,\n",
       " 'tome': 25269,\n",
       " 'fleshy': 9826,\n",
       " 'tobey': 25235,\n",
       " 'hungarians': 12191,\n",
       " 'monos': 15969,\n",
       " 'geographically': 10670,\n",
       " 'scorpions': 21850,\n",
       " 'excesses': 8889,\n",
       " 'luther': 14918,\n",
       " 'euphonious': 8766,\n",
       " 'peruse': 18248,\n",
       " 'exclaim': 8906,\n",
       " 'opposing': 17185,\n",
       " 'somewhere': 23073,\n",
       " 'thicker': 24947,\n",
       " 'lameness': 14116,\n",
       " 'focussing': 9944,\n",
       " 'apprehensive': 1227,\n",
       " 'prostrate': 19509,\n",
       " 'schoolfellows': 21808,\n",
       " 'defaced': 6254,\n",
       " 'alphonse': 788,\n",
       " 'inutility': 13428,\n",
       " 'alice': 696,\n",
       " 'redeemed': 20324,\n",
       " 'jester': 13695,\n",
       " 'kep': 13908,\n",
       " 'cusps': 5889,\n",
       " 'connection': 5021,\n",
       " 'angarola': 969,\n",
       " 'fades': 9229,\n",
       " 'expect': 9016,\n",
       " 'southern': 23162,\n",
       " 'beginnin': 2289,\n",
       " 'stray': 23800,\n",
       " 'selectman': 22080,\n",
       " 'steeples': 23617,\n",
       " 'rencounters': 20622,\n",
       " 'uniformly': 26292,\n",
       " 'mentioned': 15543,\n",
       " 'users': 26753,\n",
       " 'imprisoned': 12590,\n",
       " 'crouched': 5714,\n",
       " 'millions': 15708,\n",
       " 'claims': 4259,\n",
       " 'designed': 6597,\n",
       " 'revives': 21010,\n",
       " 'encroached': 8300,\n",
       " 'superstition': 24196,\n",
       " 'horrorless': 12065,\n",
       " 'footsteps': 10011,\n",
       " 'members': 15502,\n",
       " 'comfortless': 4633,\n",
       " 'sneer': 22935,\n",
       " 'from': 10314,\n",
       " 'jetty': 13701,\n",
       " 'truest': 25713,\n",
       " 'combed': 4602,\n",
       " 'pigs': 18432,\n",
       " 'excusable': 8926,\n",
       " 'taxidermist': 24652,\n",
       " 'shrilly': 22477,\n",
       " 'dabbled': 5943,\n",
       " 'meetings': 15475,\n",
       " 'grandeur': 11012,\n",
       " 'atal': 1621,\n",
       " 'reflecting': 20380,\n",
       " 'stampede': 23510,\n",
       " 'lol': 14722,\n",
       " 'repelling': 20670,\n",
       " 'disfigure': 7069,\n",
       " 'approximations': 1247,\n",
       " 'palin': 17604,\n",
       " 'alludes': 754,\n",
       " 'rivings': 21195,\n",
       " 'confounded': 4967,\n",
       " 'des': 6552,\n",
       " 'rub': 21360,\n",
       " 'volunteer': 27268,\n",
       " 'vext': 27053,\n",
       " 'columns': 4592,\n",
       " 'se': 21943,\n",
       " 'eirie': 8001,\n",
       " 'initiative': 13045,\n",
       " 'wager': 27337,\n",
       " 'sledge': 22792,\n",
       " 'attachments': 1658,\n",
       " 'primness': 19233,\n",
       " 'cloister': 4401,\n",
       " 'sighted': 22572,\n",
       " 'fluctuate': 9904,\n",
       " 'tolled': 25263,\n",
       " 'whereas': 27662,\n",
       " 'tamer': 24567,\n",
       " 'hushed': 12225,\n",
       " 'contiguous': 5196,\n",
       " 'sittings': 22691,\n",
       " 'stealthy': 23598,\n",
       " 'duplication': 7740,\n",
       " 'effectually': 7951,\n",
       " 'lowliness': 14840,\n",
       " 'earthly': 7830,\n",
       " 'scalp': 21736,\n",
       " 'weary': 27549,\n",
       " 'den': 6436,\n",
       " 'roberts': 21226,\n",
       " 'corresponding': 5411,\n",
       " 'steadiness': 23590,\n",
       " 'keener': 13889,\n",
       " 'impossibilities': 12557,\n",
       " 'timon': 25174,\n",
       " 'boundary': 2914,\n",
       " 'stoutness': 23750,\n",
       " 'ferment': 9526,\n",
       " 'disaster': 6960,\n",
       " 'blab': 2589,\n",
       " 'summon': 24120,\n",
       " 'unceasing': 26002,\n",
       " 'chisels': 4122,\n",
       " 'synonymous': 24478,\n",
       " 'penurious': 18058,\n",
       " 'sincerest': 22644,\n",
       " 'exclusion': 8915,\n",
       " 'fireplaces': 9695,\n",
       " 'abridge': 76,\n",
       " 'clothed': 4417,\n",
       " 'centuriones': 3833,\n",
       " 'feltspar': 9512,\n",
       " 'peace': 17941,\n",
       " 'pleasanter': 18633,\n",
       " 'nyl': 16858,\n",
       " 'sonorous': 23089,\n",
       " 'metal': 15606,\n",
       " 'attempts': 1675,\n",
       " 'spirits': 23327,\n",
       " 'cnaeus': 4455,\n",
       " 'robed': 21224,\n",
       " 'cork': 5369,\n",
       " 'comrade': 4817,\n",
       " 'downwards': 7499,\n",
       " 'uncontrollable': 26048,\n",
       " 'toy': 25386,\n",
       " 'noton': 16770,\n",
       " 'allow': 746,\n",
       " 'tempers': 24722,\n",
       " 'rinsed': 21148,\n",
       " 'husband': 12220,\n",
       " 'extravagantly': 9152,\n",
       " 'loping': 14779,\n",
       " 'naivete': 16342,\n",
       " 'reserve': 20782,\n",
       " 'lombardy': 14729,\n",
       " 'boss': 2878,\n",
       " 'jan': 13644,\n",
       " 'brentford': 3035,\n",
       " 'feeble': 9472,\n",
       " 'intricacies': 13396,\n",
       " 'displaying': 7161,\n",
       " 'gliding': 10824,\n",
       " 'andrew': 955,\n",
       " 'refract': 20391,\n",
       " 'figured': 9631,\n",
       " 'panics': 17655,\n",
       " 'signs': 22594,\n",
       " 'atone': 1646,\n",
       " 'reticence': 20914,\n",
       " 'dynamics': 7794,\n",
       " 'misery': 15810,\n",
       " 'miscellaneous': 15793,\n",
       " 'kissam': 13974,\n",
       " 'exhortation': 8980,\n",
       " 'biting': 2575,\n",
       " 'parallelisms': 17704,\n",
       " 'patrolled': 17889,\n",
       " 'tonight': 25284,\n",
       " 'incapable': 12661,\n",
       " 'swains': 24335,\n",
       " 'ripping': 21162,\n",
       " 'kryptographik': 14042,\n",
       " 'unchequered': 26015,\n",
       " 'lutes': 14917,\n",
       " 'plumed': 18682,\n",
       " 'immensely': 12439,\n",
       " 'stripped': 23856,\n",
       " 'sensed': 22118,\n",
       " 'emperors': 8211,\n",
       " 'lazily': 14279,\n",
       " 'incarnation': 12665,\n",
       " 'deliberateness': 6337,\n",
       " 'swallowing': 24338,\n",
       " 'damp': 5989,\n",
       " 'warped': 27443,\n",
       " 'aiguilles': 611,\n",
       " 'twins': 25843,\n",
       " 'represents': 20714,\n",
       " 'suppressed': 24235,\n",
       " 'candid': 3488,\n",
       " 'regulating': 20458,\n",
       " 'sxrrxws': 24433,\n",
       " 'correspondence': 5408,\n",
       " 'leaving': 14327,\n",
       " 'niggurath': 16608,\n",
       " 'morrow': 16054,\n",
       " 'asbury': 1459,\n",
       " 'congregationalists': 4998,\n",
       " 'vortex': 27286,\n",
       " 'exhalation': 8961,\n",
       " 'automaton': 1787,\n",
       " 'defensive': 6268,\n",
       " 'productions': 19328,\n",
       " 'holy': 11969,\n",
       " 'inhalation': 13020,\n",
       " 'fetichism': 9558,\n",
       " 'sooth': 23096,\n",
       " 'entering': 8482,\n",
       " 'auricula': 1752,\n",
       " 'rubbing': 21366,\n",
       " 'calmed': 3437,\n",
       " 'squall': 23424,\n",
       " 'ticket': 25123,\n",
       " 'madly': 14981,\n",
       " 'talented': 24542,\n",
       " 'poisoned': 18738,\n",
       " 'ricci': 21075,\n",
       " 'restaurant': 20859,\n",
       " 'alchemists': 664,\n",
       " 'muse': 16239,\n",
       " 'faltered': 9284,\n",
       " 'whirlingly': 27712,\n",
       " 'ami': 859,\n",
       " 'projected': 19384,\n",
       " 'guineas': 11259,\n",
       " 'infamous': 12912,\n",
       " 'fool': 9988,\n",
       " 'dormerless': 7450,\n",
       " 'endeavoured': 8321,\n",
       " 'varnish': 26889,\n",
       " 'powered': 18959,\n",
       " 'swart': 24357,\n",
       " 'plaintive': 18561,\n",
       " 'strike': 23844,\n",
       " 'overruled': 17453,\n",
       " 'colossal': 4580,\n",
       " 'cydathria': 5922,\n",
       " 'drops': 7635,\n",
       " 'fitfully': 9730,\n",
       " 'litera': 14611,\n",
       " 'supplied': 24215,\n",
       " 'magnify': 15018,\n",
       " 'colony': 4574,\n",
       " 'vad': 26796,\n",
       " 'olives': 17085,\n",
       " 'tier': 25135,\n",
       " 'compares': 4723,\n",
       " 'nightmares': 16617,\n",
       " 'arcadian': 1282,\n",
       " 'drums': 7665,\n",
       " 'dxn': 7789,\n",
       " 'artifice': 1434,\n",
       " 'lightly': 14510,\n",
       " 'mouthful': 16148,\n",
       " 'wxn': 28117,\n",
       " 'courteous': 5511,\n",
       " 'fete': 9556,\n",
       " 'pours': 18948,\n",
       " 'lowering': 14837,\n",
       " 'ardois': 1315,\n",
       " 'chatter': 3988,\n",
       " 'occurrences': 16986,\n",
       " 'tokens': 25253,\n",
       " 'innumerable': 13092,\n",
       " 'mirrored': 15776,\n",
       " 'commodity': 4682,\n",
       " 'purchase': 19695,\n",
       " 'designer': 6599,\n",
       " 'carelessly': 3606,\n",
       " 'somewhars': 23071,\n",
       " 'parallelogram': 17705,\n",
       " 'bespeaks': 2448,\n",
       " 'deserves': 6588,\n",
       " 'obligations': 16897,\n",
       " 'ancestor': 936,\n",
       " 'tharp': 24877,\n",
       " 'coma': 4594,\n",
       " 'vibration': 27065,\n",
       " 'condor': 4912,\n",
       " 'goodness': 10927,\n",
       " 'freshened': 10259,\n",
       " 'shimmer': 22373,\n",
       " 'term': 24800,\n",
       " 'caucasian': 3737,\n",
       " 'flaws': 9807,\n",
       " 'liberties': 14457,\n",
       " 'meanest': 15395,\n",
       " 'municipality': 16214,\n",
       " 'socle': 22987,\n",
       " 'genii': 10647,\n",
       " 'covetously': 5535,\n",
       " 'cards': 3597,\n",
       " 'warriors': 27450,\n",
       " 'divulged': 7333,\n",
       " 'arousing': 1387,\n",
       " 'reform': 20388,\n",
       " 'destroyers': 6660,\n",
       " 'fearlessness': 9445,\n",
       " 'animating': 1001,\n",
       " 'civic': 4243,\n",
       " 'planning': 18579,\n",
       " 'forces': 10029,\n",
       " 'keen': 13888,\n",
       " 'progenitors': 19368,\n",
       " 'hearing': 11622,\n",
       " 'deposited': 6498,\n",
       " 'vibrations': 27066,\n",
       " 'cow': 5537,\n",
       " 'uninscribable': 26311,\n",
       " 'slayer': 22788,\n",
       " 'lashed': 14198,\n",
       " 'remorseless': 20603,\n",
       " 'zit': 28267,\n",
       " 'rob': 21216,\n",
       " 'angekok': 970,\n",
       " 'revelation': 20963,\n",
       " 'fosterage': 10147,\n",
       " 'laxity': 14272,\n",
       " 'barren': 2090,\n",
       " 'oppodeldoc': 17175,\n",
       " 'invoked': 13482,\n",
       " 'martyred': 15265,\n",
       " 'butterfly': 3332,\n",
       " 'wells': 27604,\n",
       " 'secretaries': 21999,\n",
       " 'bachelor': 1922,\n",
       " 'jacket': 13629,\n",
       " 'agent': 548,\n",
       " 'zenobia': 28251,\n",
       " 'twirled': 25845,\n",
       " 'minotaur': 15759,\n",
       " 'weariness': 27545,\n",
       " 'tie': 25132,\n",
       " 'available': 1799,\n",
       " 'aeras': 459,\n",
       " 'huguenot': 12145,\n",
       " 'theirselves': 24896,\n",
       " 'theodore': 24906,\n",
       " 'checked': 4006,\n",
       " 'fitten': 9735,\n",
       " 'insieme': 13146,\n",
       " 'division': 7328,\n",
       " 'cocoa': 4493,\n",
       " 'acclamation': 159,\n",
       " 'caravans': 3585,\n",
       " 'canvassed': 3530,\n",
       " 'owner': 17512,\n",
       " 'given': 10773,\n",
       " 'charnel': 3968,\n",
       " 'member': 15501,\n",
       " 'commingled': 4670,\n",
       " 'metamorphosed': 15610,\n",
       " 'eyeless': 9181,\n",
       " 'kanaky': 13872,\n",
       " 'relume': 20553,\n",
       " 'auguries': 1734,\n",
       " 'mynheer': 16300,\n",
       " 'cracking': 5560,\n",
       " 'lion': 14575,\n",
       " 'begone': 2294,\n",
       " 'acts': 282,\n",
       " 'trowel': 25701,\n",
       " 'malignant': 15091,\n",
       " 'sx': 24432,\n",
       " 'comedian': 4614,\n",
       " 'suffers': 24062,\n",
       " 'revolt': 21016,\n",
       " 'plodding': 18661,\n",
       " 'identifiable': 12311,\n",
       " 'collector': 4549,\n",
       " 'vankirk': 26859,\n",
       " 'managing': 15119,\n",
       " 'impost': 12561,\n",
       " 'miracles': 15770,\n",
       " 'dover': 7484,\n",
       " 'themselves': 24900,\n",
       " 'twinge': 25839,\n",
       " 'royal': 21354,\n",
       " 'undulating': 26155,\n",
       " 'ghastly': 10708,\n",
       " 'worthy': 28036,\n",
       " 'seben': 21982,\n",
       " 'thet': 24942,\n",
       " 'leaping': 14309,\n",
       " 'enquiry': 8445,\n",
       " 'weren': 27611,\n",
       " 'numberless': 16822,\n",
       " 'cottage': 5444,\n",
       " 'alliances': 741,\n",
       " 'duck': 7690,\n",
       " 'ins': 13118,\n",
       " 'bindings': 2546,\n",
       " 'braying': 2995,\n",
       " 'bug': 3209,\n",
       " 'tension': 24783,\n",
       " 'rigidity': 21128,\n",
       " 'barely': 2055,\n",
       " 'card': 3593,\n",
       " 'torments': 25319,\n",
       " 'redundance': 20340,\n",
       " 'leash': 14319,\n",
       " 'little': 14626,\n",
       " 'statement': 23557,\n",
       " 'swap': 24349,\n",
       " 'discovery': 7033,\n",
       " 'vellum': 26939,\n",
       " 'archon': 1306,\n",
       " 'encumbrances': 8307,\n",
       " 'sixpence': 22697,\n",
       " 'doorbell': 7437,\n",
       " 'decomposing': 6202,\n",
       " 'persuasion': 18229,\n",
       " 'tangible': 24575,\n",
       " 'omission': 17102,\n",
       " 'drink': 7596,\n",
       " 'garages': 10535,\n",
       " 'premium': 19098,\n",
       " 'illinois': 12368,\n",
       " 'badly': 1939,\n",
       " 'whines': 27697,\n",
       " 'hesitantly': 11808,\n",
       " 'gesticulations': 10694,\n",
       " 'tissued': 25213,\n",
       " 'rationale': 20072,\n",
       " 'bolting': 2807,\n",
       " 'spirals': 23321,\n",
       " 'smuggle': 22913,\n",
       " 'fairy': 9257,\n",
       " 'gaillard': 10467,\n",
       " 'legislative': 14372,\n",
       " 'developed': 6720,\n",
       " 'powerfully': 18961,\n",
       " 'luton': 14919,\n",
       " 'ultimate': 25899,\n",
       " 'peninsula': 18035,\n",
       " 'plastering': 18590,\n",
       " 'highness': 11856,\n",
       " 'dismal': 7115,\n",
       " 'tracing': 25395,\n",
       " 'disorderly': 7134,\n",
       " 'honesti': 11996,\n",
       " 'cordiality': 5357,\n",
       " 'nausea': 16419,\n",
       " 'blend': 2661,\n",
       " 'theatre': 24887,\n",
       " 'lambs': 14113,\n",
       " 'qualm': 19802,\n",
       " 'numbered': 16821,\n",
       " 'critic': 5679,\n",
       " 'move': 16153,\n",
       " 'carousing': 3632,\n",
       " 'die': 6818,\n",
       " 'politician': 18764,\n",
       " 'irregular': 13533,\n",
       " 'sidled': 22553,\n",
       " 'grass': 11042,\n",
       " 'strangle': 23787,\n",
       " 'withdraw': 27904,\n",
       " 'ud': 25888,\n",
       " 'emigration': 8194,\n",
       " 'rustling': 21455,\n",
       " 'æschylus': 28292,\n",
       " 'effulgence': 7966,\n",
       " 'stoutest': 23748,\n",
       " 'misinformed': 15816,\n",
       " 'irreparably': 13541,\n",
       " 'newport': 16572,\n",
       " 'newcomer': 16566,\n",
       " 'bustled': 3317,\n",
       " 'betrays': 2478,\n",
       " 'practitioner': 18979,\n",
       " 'indiscriminately': 12824,\n",
       " 'sobriety': 22976,\n",
       " 'unassuming': 25948,\n",
       " 'unreal': 26479,\n",
       " 'commit': 4675,\n",
       " 'neatness': 16452,\n",
       " 'av': 1796,\n",
       " 'ruins': 21402,\n",
       " 'disturbs': 7290,\n",
       " 'cooked': 5319,\n",
       " 'ise': 13569,\n",
       " 'patois': 17878,\n",
       " 'constantinopolis': 5107,\n",
       " 'substantiality': 24002,\n",
       " 'victorian': 27082,\n",
       " 'instantly': 13195,\n",
       " 'anastasia': 928,\n",
       " 'electrical': 8046,\n",
       " 'gave': 10601,\n",
       " 'bleitziz': 2657,\n",
       " 'june': 13819,\n",
       " 'sheet': 22338,\n",
       " 'carryin': 3648,\n",
       " 'owing': 17506,\n",
       " 'footrace': 10009,\n",
       " 'clandestinely': 4276,\n",
       " 'confidently': 4945,\n",
       " 'adventure': 419,\n",
       " 'intrude': 13409,\n",
       " 'reunion': 20955,\n",
       " 'grabs': 10979,\n",
       " 'depreciations': 6514,\n",
       " 'gone': 10921,\n",
       " 'shun': 22509,\n",
       " 'herbage': 11765,\n",
       " 'wyatt': 28121,\n",
       " 'farmyard': 9344,\n",
       " 'salis': 21547,\n",
       " 'complimented': 4780,\n",
       " 'supernal': 24188,\n",
       " 'extolled': 9137,\n",
       " 'endeavours': 8323,\n",
       " 'councils': 5461,\n",
       " 'polypheme': 18779,\n",
       " 'sarten': 21643,\n",
       " 'destroying': 6661,\n",
       " 'spasmodic': 23213,\n",
       " 'seed': 22036,\n",
       " 'hospitality': 12078,\n",
       " 'dressing': 7585,\n",
       " 'punctured': 19676,\n",
       " 'fettered': 9562,\n",
       " 'crooked': 5699,\n",
       " 'shaded': 22258,\n",
       " 'meanness': 15402,\n",
       " 'tape': 24591,\n",
       " 'squeezing': 23450,\n",
       " 'consisted': 5077,\n",
       " 'chiefless': 4063,\n",
       " 'abrupt': 79,\n",
       " 'parting': 17797,\n",
       " 'deity': 6323,\n",
       " 'logically': 14713,\n",
       " 'sardanapalus': 21634,\n",
       " 'unreasonably': 26484,\n",
       " 'intuitive': 13419,\n",
       " 'chagrined': 3866,\n",
       " 'distributio': 7277,\n",
       " 'instability': 13183,\n",
       " 'engraving': 8380,\n",
       " 'protraction': 19537,\n",
       " 'advised': 445,\n",
       " 'least': 14320,\n",
       " 'vest': 27036,\n",
       " 'overlooking': 17440,\n",
       " 'breathings': 3019,\n",
       " 'rosaries': 21294,\n",
       " 'seaweed': 21981,\n",
       " 'superhuman': 24175,\n",
       " 'anglois': 986,\n",
       " 'fillagree': 9643,\n",
       " 'purring': 19732,\n",
       " 'drum': 7661,\n",
       " 'fragrant': 10189,\n",
       " 'bafflement': 1942,\n",
       " 'descend': 6559,\n",
       " 'fling': 9844,\n",
       " 'islanded': 13575,\n",
       " 'bond': 2818,\n",
       " 'counsel': 5462,\n",
       " 'decision': 6177,\n",
       " 'equalling': 8607,\n",
       " 'shrubberies': 22493,\n",
       " 'motions': 16102,\n",
       " 'breach': 2998,\n",
       " 'frightful': 10292,\n",
       " 'perused': 18249,\n",
       " 'gushed': 11288,\n",
       " 'hated': 11538,\n",
       " 'tall': 24553,\n",
       " 'echoing': 7878,\n",
       " 'dived': 7299,\n",
       " 'ts': 25736,\n",
       " 'subjeck': 23957,\n",
       " 'pull': 19646,\n",
       " 'liverpool': 14637,\n",
       " 'assert': 1539,\n",
       " 'eustache': 8773,\n",
       " 'abominably': 59,\n",
       " 'inestimable': 12892,\n",
       " 'comedy': 4616,\n",
       " 'constructed': 5124,\n",
       " 'educe': 7925,\n",
       " 'echec': 7874,\n",
       " 'flounces': 9885,\n",
       " 'impertinence': 12511,\n",
       " 'markbrünnen': 15221,\n",
       " 'centumcellae': 3829,\n",
       " 'persevering': 18198,\n",
       " 'mentoni': 15546,\n",
       " 'ceremonials': 3840,\n",
       " 'rice': 21076,\n",
       " 'bids': 2519,\n",
       " 'etienne': 8751,\n",
       " 'thickets': 24950,\n",
       " 'abstain': 97,\n",
       " 'illustrate': 12385,\n",
       " 'falconer': 9264,\n",
       " 'dealings': 6108,\n",
       " 'zober': 28269,\n",
       " 'inessential': 12891,\n",
       " 'superintendence': 24181,\n",
       " 'sprinkled': 23398,\n",
       " 'cinnamon': 4201,\n",
       " 'offence': 17034,\n",
       " 'trever': 25601,\n",
       " 'exult': 9166,\n",
       " 'rowers': 21350,\n",
       " 'sweat': 24370,\n",
       " 'rant': 20023,\n",
       " 'haunt': 11555,\n",
       " 'borne': 2868,\n",
       " 'drowning': 7645,\n",
       " 'leathern': 14322,\n",
       " 'afield': 518,\n",
       " 'immaculateness': 12424,\n",
       " 'hate': 11537,\n",
       " 'hills': 11864,\n",
       " 'alternation': 808,\n",
       " 'befouled': 2275,\n",
       " 'booming': 2843,\n",
       " 'takin': 24535,\n",
       " 'court': 5509,\n",
       " 'designate': 6593,\n",
       " 'hovels': 12116,\n",
       " 'insensibly': 13135,\n",
       " 'beauvais': 2219,\n",
       " 'betokened': 2471,\n",
       " 'mercurie': 15560,\n",
       " 'sheltering': 22346,\n",
       " 'bushy': 3306,\n",
       " 'castle': 3692,\n",
       " 'forenoon': 10053,\n",
       " 'hippodrome': 11888,\n",
       " 'revis': 21002,\n",
       " 'widower': 27782,\n",
       " 'quainter': 19789,\n",
       " 'wakefield': 27365,\n",
       " 'hut': 12230,\n",
       " 'intrench': 13394,\n",
       " 'lift': 14494,\n",
       " 'dies': 6822,\n",
       " 'caller': 3428,\n",
       " 'xwl': 28138,\n",
       " 'zo': 28268,\n",
       " 'unreservedly': 26510,\n",
       " 'palladian': 17609,\n",
       " 'binder': 2544,\n",
       " 'blemished': 2659,\n",
       " 'fixing': 9744,\n",
       " 'sonnets': 23088,\n",
       " 'describing': 6572,\n",
       " 'sharers': 22307,\n",
       " 'distantly': 7238,\n",
       " 'ideal': 12302,\n",
       " 'ritzner': 21181,\n",
       " 'unalterable': 25930,\n",
       " 'enveloping': 8552,\n",
       " 'grieving': 11129,\n",
       " 'rectangle': 20307,\n",
       " 'smitherton': 22894,\n",
       " 'archaic': 1290,\n",
       " 'organism': 17238,\n",
       " 'in': 12623,\n",
       " 'canaries': 3480,\n",
       " 'grieved': 11128,\n",
       " 'proprieties': 19481,\n",
       " 'coir': 4522,\n",
       " 'baffled': 1941,\n",
       " 'sabines': 21478,\n",
       " 'receptive': 20217,\n",
       " 'snug': 22956,\n",
       " 'raged': 19951,\n",
       " 'hurling': 12207,\n",
       " 'sam': 21572,\n",
       " 'tenements': 24773,\n",
       " 'benign': 2394,\n",
       " 'twists': 25852,\n",
       " 'haeckel': 11343,\n",
       " 'pensioners': 18048,\n",
       " 'feerd': 9486,\n",
       " 'considerations': 5070,\n",
       " 'mourn': 16136,\n",
       " 'skulking': 22744,\n",
       " 'nariel': 16373,\n",
       " 'being': 2316,\n",
       " 'fronts': 10321,\n",
       " 'counterfeits': 5478,\n",
       " 'officials': 17053,\n",
       " 'population': 18830,\n",
       " 'penning': 18043,\n",
       " 'handiwork': 11402,\n",
       " 'dunwich': 7733,\n",
       " 'should': 22438,\n",
       " 'buried': 3277,\n",
       " 'incitement': 12687,\n",
       " 'observant': 16924,\n",
       " 'upward': 26721,\n",
       " 'hanged': 11419,\n",
       " 'hermetically': 11787,\n",
       " 'effudit': 7965,\n",
       " 'taken': 24533,\n",
       " 'priestley': 19219,\n",
       " 'cubs': 5790,\n",
       " 'latour': 14226,\n",
       " 'protruding': 19539,\n",
       " 'sweeps': 24377,\n",
       " 'bay': 2166,\n",
       " 'brother': 3134,\n",
       " 'presentiments': 19138,\n",
       " 'finny': 9684,\n",
       " 'onerous': 17122,\n",
       " 'lightening': 14504,\n",
       " 'tribal': 25609,\n",
       " 'drivers': 7607,\n",
       " 'backgrounds': 1926,\n",
       " 'pagans': 17557,\n",
       " 'loves': 14828,\n",
       " 'mousseux': 16145,\n",
       " 'descriptive': 6576,\n",
       " 'purloiner': 19719,\n",
       " 'parlour': 17754,\n",
       " 'sacrifised': 21494,\n",
       " 'fearfully': 9441,\n",
       " 'sagacious': 21515,\n",
       " 'speculating': 23266,\n",
       " 'plum': 18676,\n",
       " 'abilities': 42,\n",
       " 'came': 3451,\n",
       " 'fleece': 9813,\n",
       " 'persecutors': 18189,\n",
       " 'impelling': 12488,\n",
       " 'inventive': 13446,\n",
       " 'exercise': 8950,\n",
       " 'labored': 14055,\n",
       " 'bixby': 2585,\n",
       " 'lashes': 14199,\n",
       " 'divided': 7316,\n",
       " 'ingenuity': 12996,\n",
       " 'bedpost': 2248,\n",
       " 'jefferson': 13671,\n",
       " 'thicket': 24949,\n",
       " 'hound': 12098,\n",
       " 'mischief': 15796,\n",
       " 'suitable': 24086,\n",
       " 'intitul': 13378,\n",
       " 'professionally': 19342,\n",
       " 'visual': 27209,\n",
       " 'tickle': 25126,\n",
       " 'assuage': 1574,\n",
       " 'generated': 10632,\n",
       " 'extends': 9114,\n",
       " 'sufficiently': 24067,\n",
       " 'annex': 1012,\n",
       " 'strangeness': 23782,\n",
       " 'shuffle': 22506,\n",
       " 'chieftains': 4066,\n",
       " 'unfounded': 26236,\n",
       " 'meridian': 15570,\n",
       " 'scribbler': 21899,\n",
       " 'uncomplainingly': 26036,\n",
       " 'say': 21718,\n",
       " 'drawers': 7546,\n",
       " 'counterfeit': 5476,\n",
       " 'madam': 14970,\n",
       " 'besieging': 2442,\n",
       " 'rainy': 19977,\n",
       " 'dissolve': 7227,\n",
       " 'amaze': 827,\n",
       " 'tolerably': 25257,\n",
       " 'fervour': 9544,\n",
       " 'handful': 11399,\n",
       " 'invited': 13477,\n",
       " 'chi': 4052,\n",
       " 'cautious': 3754,\n",
       " 'nailed': 16338,\n",
       " 'wealthy': 27533,\n",
       " 'despot': 6645,\n",
       " 'lizard': 14648,\n",
       " 'poorest': 18814,\n",
       " 'stealthily': 23597,\n",
       " 'ignominy': 12350,\n",
       " 'unexplainable': 26193,\n",
       " 'sharper': 22312,\n",
       " 'ugh': 25890,\n",
       " 'ruffle': 21389,\n",
       " 'directorium': 6921,\n",
       " 'cut': 5899,\n",
       " 'favor': 9419,\n",
       " 'nervous': 16530,\n",
       " 'compelled': 4738,\n",
       " 'inappropriateness': 12646,\n",
       " 'crucible': 5730,\n",
       " 'loth': 14797,\n",
       " 'curious': 5849,\n",
       " 'loved': 14819,\n",
       " 'filtered': 9656,\n",
       " 'bright': 3070,\n",
       " 'oceanic': 16990,\n",
       " 'rifkin': 21113,\n",
       " 'towered': 25378,\n",
       " 'schemed': 21787,\n",
       " 'cartilaginous': 3657,\n",
       " 'adelaide': 323,\n",
       " 'prisons': 19264,\n",
       " 'abbé': 21,\n",
       " 'governed': 10969,\n",
       " 'prove': 19544,\n",
       " 'lustreless': 14910,\n",
       " 'uprose': 26711,\n",
       " ...}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "dataset = train.append(test)\n",
    "dataset.shape\n",
    "word_dict = CountVectorizer().fit(dataset[\"text\"])\n",
    "word_dict.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(list(word_dict.vocabulary_.values())).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>encoded</th>\n",
       "      <th>encoded_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[24989, 19300, 12122, 510, 15383, 16655, 15403...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[13597, 16557, 17117, 16984, 25229, 15383, 248...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[12623, 11895, 14354, 11396, 27455, -1, 10914,...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[12121, 14825, 13566, 23392, 1456, 27520, 1475...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[9667, 16753, 8113, 16744, 8784, 10914, 24886,...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                             encoded  encoded_len  \n",
       "0  [24989, 19300, 12122, 510, 15383, 16655, 15403...           41  \n",
       "1  [13597, 16557, 17117, 16984, 25229, 15383, 248...           14  \n",
       "2  [12623, 11895, 14354, 11396, 27455, -1, 10914,...           36  \n",
       "3  [12121, 14825, 13566, 23392, 1456, 27520, 1475...           34  \n",
       "4  [9667, 16753, 8113, 16744, 8784, 10914, 24886,...           27  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "invalid_word_idx = -1\n",
    "\n",
    "train[\"encoded\"] = train[\"text\"].apply(lambda x: \n",
    "                              [word_dict.vocabulary_[word.lower()] \n",
    "                               if word.lower() in word_dict.vocabulary_ \n",
    "                               else invalid_word_idx\n",
    "                               for word in word_tokenize(x) \n",
    "                               if word.isalpha() ])\n",
    "train[\"encoded_len\"] = train[\"encoded\"].apply(lambda x: len(x))\n",
    "train[:5]                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19579.000000\n",
       "mean        26.639512\n",
       "std         19.003268\n",
       "min          0.000000\n",
       "25%         15.000000\n",
       "50%         23.000000\n",
       "75%         34.000000\n",
       "max        862.000000\n",
       "Name: encoded_len, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"encoded_len\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Явно има изречения с по 0 думи, ще ги филтрирам не виждам как ще носят информация :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19572.000000\n",
       "mean        26.648426\n",
       "std         19.000813\n",
       "min          3.000000\n",
       "25%         15.000000\n",
       "50%         23.000000\n",
       "75%         34.000000\n",
       "max        862.000000\n",
       "Name: encoded_len, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train [train[\"encoded_len\"] > 2]\n",
    "train[\"encoded_len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sentence_len = int(train[\"encoded_len\"].describe()[\"max\"])\n",
    "max_sentence_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ще подравня всички изречения да имат равен брой думи, за да мога да ползвам фиксиран ембединг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded</th>\n",
       "      <th>encoded_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[24989, 19300, 12122, 510, 15383, 16655, 15403...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[13597, 16557, 17117, 16984, 25229, 15383, 248...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12623, 11895, 14354, 11396, 27455, -1, 10914,...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[12121, 14825, 13566, 23392, 1456, 27520, 1475...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9667, 16753, 8113, 16744, 8784, 10914, 24886,...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             encoded  encoded_len\n",
       "0  [24989, 19300, 12122, 510, 15383, 16655, 15403...          862\n",
       "1  [13597, 16557, 17117, 16984, 25229, 15383, 248...          862\n",
       "2  [12623, 11895, 14354, 11396, 27455, -1, 10914,...          862\n",
       "3  [12121, 14825, 13566, 23392, 1456, 27520, 1475...          862\n",
       "4  [9667, 16753, 8113, 16744, 8784, 10914, 24886,...          862"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded = pd.DataFrame()\n",
    "def padd_sentence(sentence):\n",
    "    diff = max_sentence_len - len(sentence)\n",
    "    for _ in range(diff):\n",
    "        sentence.append(invalid_word_idx)\n",
    "    \n",
    "    return sentence\n",
    "    \n",
    "train_padded[\"encoded\"] = train[\"encoded\"].apply(padd_sentence)\n",
    "train_padded[\"encoded_len\"] = train_padded[\"encoded\"].apply(lambda x: len(x))\n",
    "train_padded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19572, 862)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array([ sentence for sentence in train_padded[\"encoded\"]])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19572, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"author\"] = train[\"author\"].replace(\"EAP\",0)\n",
    "train[\"author\"] = train[\"author\"].replace(\"HPL\",1)\n",
    "train[\"author\"] = train[\"author\"].replace(\"MWS\",2)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_train = OneHotEncoder().fit_transform(train[\"author\"].as_matrix().reshape(-1, 1))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Embedding, Bidirectional, Input, LSTM, Bidirectional\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8676499918070679944\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2534080512\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 7368396669237492378\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_sentence_len,))\n",
    "embedding_layer = Embedding(input_dim=max_sentence_len, output_dim=128 )\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_lstm = Bidirectional(LSTM(128))(embedded_sequences)\n",
    "preds = Dense(3, activation=\"softmax\")(l_lstm)\n",
    "model = Model(sequence_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 862)               0         \n",
      "_________________________________________________________________\n",
      "embedding_27 (Embedding)     (None, 862, 128)          110336    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 374,275\n",
      "Trainable params: 374,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,epochs=16, validation_split=0.2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bidirection_lstm.h5\") # loss > 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ще пробвам нов модел с по-малък embedding layer и 1 lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_sentence_len,))\n",
    "embedding_layer = Embedding(input_dim=max_sentence_len, output_dim=64 )\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "lstm = LSTM(64)(embedded_sequences)\n",
    "preds = Dense(3, activation=\"softmax\")(lstm)\n",
    "model = Model(sequence_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"acc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,epochs=12, validation_split=0.2, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm.h5\") # loss > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не постигнах кой знае какъв успех, ще пробвам още веднъж с различен оптимизатор и регуларизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_sentence_len, output_dim=128),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_44 (Embedding)     (None, 862, 128)          110336    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 862, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 110336)            0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 226)               24936162  \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 226)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 3)                 681       \n",
      "=================================================================\n",
      "Total params: 25,047,179\n",
      "Trainable params: 25,047,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=512,epochs=15,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wont save it loss > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ще пробвам и с нормална feed forward, но с embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Dropout, Reshape, Flatten\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(max_sentence_len, 84, input_length=max_sentence_len),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"tanh\"),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"tanh\"),\n",
    "    Dense(16, activation=\"tanh\"),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 862, 84)           72408     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 862, 84)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 72408)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4634176   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 4,709,243\n",
      "Trainable params: 4,709,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15657 samples, validate on 3915 samples\n",
      "Epoch 1/12\n",
      "15657/15657 [==============================] - 2s 140us/step - loss: 1.0933 - acc: 0.4049 - val_loss: 1.0905 - val_acc: 0.4061\n",
      "Epoch 2/12\n",
      "15657/15657 [==============================] - 2s 123us/step - loss: 1.0799 - acc: 0.4139 - val_loss: 1.0937 - val_acc: 0.4059\n",
      "Epoch 3/12\n",
      "15657/15657 [==============================] - 2s 123us/step - loss: 1.0535 - acc: 0.4404 - val_loss: 1.0869 - val_acc: 0.4314\n",
      "Epoch 4/12\n",
      "15657/15657 [==============================] - 2s 123us/step - loss: 1.0222 - acc: 0.4836 - val_loss: 1.1266 - val_acc: 0.4268\n",
      "Epoch 5/12\n",
      "15657/15657 [==============================] - 2s 122us/step - loss: 1.0266 - acc: 0.4865 - val_loss: 1.1070 - val_acc: 0.4207\n",
      "Epoch 6/12\n",
      "15657/15657 [==============================] - 2s 124us/step - loss: 1.0245 - acc: 0.4821 - val_loss: 1.0973 - val_acc: 0.4204\n",
      "Epoch 7/12\n",
      "15657/15657 [==============================] - 2s 124us/step - loss: 1.0241 - acc: 0.4808 - val_loss: 1.1053 - val_acc: 0.4197\n",
      "Epoch 8/12\n",
      "15657/15657 [==============================] - 2s 123us/step - loss: 1.0214 - acc: 0.4795 - val_loss: 1.1076 - val_acc: 0.4082\n",
      "Epoch 9/12\n",
      "15657/15657 [==============================] - 2s 122us/step - loss: 1.0250 - acc: 0.4758 - val_loss: 1.1043 - val_acc: 0.4133\n",
      "Epoch 10/12\n",
      "15657/15657 [==============================] - 2s 123us/step - loss: 1.0247 - acc: 0.4737 - val_loss: 1.1011 - val_acc: 0.4107\n",
      "Epoch 11/12\n",
      "15657/15657 [==============================] - 2s 124us/step - loss: 1.0226 - acc: 0.4753 - val_loss: 1.1040 - val_acc: 0.4069\n",
      "Epoch 12/12\n",
      "15657/15657 [==============================] - 2s 123us/step - loss: 1.0234 - acc: 0.4748 - val_loss: 1.1113 - val_acc: 0.4066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7394691d30>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256,epochs=12,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
